{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIgO3haW10Oemgjm6JQ5ri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komalaftab/piaic_assignment_Q3/blob/main/chapter_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCoDGYsbUabg"
      },
      "source": [
        "**Listing 7.1::**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjxFRohGUiqf"
      },
      "source": [
        "**Importing libraies::**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iii0o9uUT_T"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbQ89mQ-Uyci"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWWd8AxFYK4e",
        "outputId": "7bcde0a8-70e2-4545-c5cf-fd1a400d587d"
      },
      "source": [
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "# The text input is a variable-length sequence of integers. Note that you can optionally name the inputs.\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "# Embeds the inputs into a sequence of vectors of size 64\n",
        "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)\n",
        "# Encodes the vectors in a single vector via an LSTM\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "# Same process (with different layer instances) for the question\n",
        "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
        "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)\n",
        "\n",
        "# Concatenates the encoded question and encoded text\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
        "# Adds a softmax classifier on top\n",
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
        "\n",
        "# At model instantiation, you specify the two inputs and the output.\n",
        "model = Model([text_input, question_input], answer)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 32)           12416       embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 16)           3136        embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 48)           0           lstm_4[0][0]                     \n",
            "                                                                 lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 500)          24500       concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,000,052\n",
            "Trainable params: 1,000,052\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT-N5KR2ndO4",
        "outputId": "08ab9efa-1a3a-4de7-ec57-44704248a4b7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "# Generates dummy Numpy data\n",
        "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
        "\n",
        "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
        "# Answers are one-hot encoded, not integers\n",
        "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
        "\n",
        "# Fitting using a list of inputs\n",
        "model.fit([text, question], answers, epochs=10, batch_size=128)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 5s 138ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 136ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 140ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 135ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 133ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 129ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 122ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 109ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 110ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 112ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2fc9e63190>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRh5Z63GnsuK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}